{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python\n",
    "\n",
    "Welcome to the **Deep Learning** course! This course is designed to give you hands-on experience with the foundational concepts and advanced techniques in deep learning. You will explore:\n",
    "\n",
    "- Artificial Neural Networks and Gradient Descent\n",
    "- Convolutional Neural Networks (CNNs) for Computer Vision\n",
    "- Recurrent Neural Networks (RNNs) for Text Prediction\n",
    "- Diffusion Transformers for Image Generation\n",
    "\n",
    "Throughout the course, you'll engage in projects to solidify your understanding and gain practical skills in implementing deep learning algorithms.  \n",
    "\n",
    "Instructor: Dr. Adrien Dorise  \n",
    "Contact: adrien.dorise@hotmail.com  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Convolutional Neural Networks\n",
    "\n",
    "In this project, you will leanr how to handle more complex datasets and how to create a CNN model to make predictions on image datasets.  \n",
    "Many Python packages can be used to work with Deep Learning (Scikit-learn, Tensorflow, Keras...). In this project, we will used **PyTorch**, as it is the most popular at the moment.    \n",
    "`https://pytorch.org/`\n",
    "\n",
    "\n",
    "This project tis organised as follow:\n",
    "\n",
    "### 1. Data Management\n",
    "**1.1 Data Downloading**\n",
    "- **Objective**: Acquire the dataset required for training and evaluation.\n",
    "- **Steps**:\n",
    "  - Identify a suitable dataset (e.g., CIFAR-10, ImageNet, or a custom dataset).\n",
    "  - Download the dataset and organize it into appropriate directories for easy access.\n",
    "\n",
    "**1.2 Train/Validation/Test Split**\n",
    "\n",
    "- **Objective**: Divide the dataset into training, validation, and test sets to ensure unbiased evaluation.\n",
    "- **Steps**:\n",
    "  - Allocate a percentage of the data for training (e.g., 70%), validation (e.g., 15%), and testing (e.g., 15%).\n",
    "  - Ensure that each set is representative of the overall dataset.\n",
    "\n",
    "**1.3 Shuffling**\n",
    "\n",
    "- **Objective**: Randomize the order of data samples to prevent any inherent ordering biases.\n",
    "- **Steps**:\n",
    "  - Implement shuffling during data loading to ensure that the model does not learn any unintended patterns.\n",
    "\n",
    "**1.4 Creation of Data Loader**\n",
    "\n",
    "- **Objective**: Efficiently load data in batches for training and evaluation.\n",
    "- **Steps**:\n",
    "  - Utilize data loader utilities provided by deep learning frameworks to handle batching, shuffling, and augmentation.\n",
    "\n",
    "### 2. Model Creation\n",
    "\n",
    "**2.1 CNN from Scratch**\n",
    "\n",
    "- **Objective**: Build a custom CNN architecture tailored to the specific dataset.\n",
    "- **Steps**:\n",
    "  - Define the architecture with appropriate layers (e.g., convolutional, pooling, fully connected).\n",
    "  - Choose activation functions, loss functions, and optimizers.\n",
    "  - Compile and summarize the model to review its structure.\n",
    "\n",
    "**2.2 CNN from Foundation Model and Fine-Tuning**\n",
    "\n",
    "- **Objective**: Leverage pre-trained models to improve performance and reduce training time.\n",
    "- **Steps**:\n",
    "  - Select a pre-trained model (e.g., VGG16, ResNet50) relevant to the task.\n",
    "  - Replace the final layers to match the number of classes in the dataset.\n",
    "  - Freeze initial layers to retain learned features and fine-tune subsequent layers on the new dataset.\n",
    "\n",
    "### 3. Results\n",
    "\n",
    "**3.1 Plotting Training Curve**\n",
    "\n",
    "- **Objective**: Visualize the model's performance over epochs.\n",
    "- **Steps**:\n",
    "  - Plot training and validation accuracy to assess learning progress.\n",
    "  - Plot training and validation loss to identify potential overfitting or underfitting.\n",
    "\n",
    "**3.2 Visualize Images and Predictions**\n",
    "\n",
    "- **Objective**: Evaluate the model's predictions on sample images.\n",
    "- **Steps**:\n",
    "  - Display a set of test images alongside their predicted and true labels.\n",
    "  - Highlight correctly classified and misclassified examples to gain insights into model performance.\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "In this exercise, we will use the **CIFAR-10 dataset**.  \n",
    "\n",
    "The CIFAR (Canadian Institute For Advanced Research) datasets are a collection of images widely used for training machine learning and computer vision algorithms. There are two primary versions:\n",
    "\n",
    "### CIFAR-10\n",
    "\n",
    "- Description: Consists of 60,000 color images, each of size 32x32 pixels, categorized into 10 distinct classes.\n",
    "- Classes: Airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.  \n",
    "\n",
    "This dataset is commonly used for benchmarking image classification algorithms.\n",
    "### CIFAR-100\n",
    "\n",
    "- Description: Similar to CIFAR-10, it is comprised of 100 classes, with 600 images per class.\n",
    "- Classes: Each class contains 500 training images and 100 testing images.  \n",
    "\n",
    "The increased number of classes in CIFAR-100 provides a more challenging classification task compared to CIFAR-10.\n",
    "\n",
    "\n",
    "You can find more details here:\n",
    "`https://www.cs.toronto.edu/~kriz/cifar.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Data Downloading\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((112,112)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5),)])\n",
    "cifar10_train = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "cifar10_test = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                        download=True, transform=transform)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validation / Split\n",
    "\n",
    "When training a model, it is usual to divide the whole dataset into three distinct subdatasets: training, validation and test sets.\n",
    "- **Training set**: Portion of the data used to train the model during the *training phase*. During this phase, the model learns the patterns of the data by adjusting its parameters\n",
    "- **Validation set**: Portion of the data used to verify the training process during the *training phase*. The performance of the validation set relative to the test set can help prevent overfitting.  The model's parameters are not updated while going through the validation set.\n",
    "- **Test set**: Portion of the data used as final validation for the model performance. It assesses the model performance on unseen data. It is the closest evaluation of the model on *production data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/Validation/Test split\n",
    "train_size = int(0.8 * len(cifar10_train))\n",
    "val_size = len(cifar10_train) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(cifar10_train, [train_size, val_size])\n",
    "\n",
    "# 1.5 Creation of Data Loader\n",
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True,)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images\n",
    "\n",
    "Now that you have your three data loader containing your images and classes, you can try to plot the images to understand how to interact with the dataloader. Don't hesitate to modify the parameters to understand what they do.  \n",
    "\n",
    "Answer the following questions:\n",
    "- What is the purpose of the *train_size* variable? What should be (approximately) its range?\n",
    "- What is the use of the *shuffle* parameter? Why is it set to *True* for the train data loader, and not the others?\n",
    "- What is the use of *batch_size*?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get a batch of images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN model\n",
    "\n",
    "<img src=\"../docs/cnn.jpg\" alt=\"Perceptron\" width=\"500\"/> \n",
    "\n",
    "As seen during the course, a CNN is composed of three distincts section:\n",
    "- A convolution encoder that extracts the features. It is composed of:\n",
    "    - Convolutional layers\n",
    "    - Pooling layers\n",
    "- A flattening layer to link the convolutional section with the fully connected section\n",
    "- A fully connected decoder that makes predictions out of the encoded features.  \n",
    "\n",
    "By using PyTorch, you will have to recreate each of these layers and sepcify their connections with each others.\n",
    "\n",
    "- Complete the *CNN* class below to create a CNN model.\n",
    "- Define the architecture of the neural network in the *__init__* method\n",
    "  - Convolutional layer: nn.Conv2d(n_channels_input, n_channels_output, kernel_size, padding, stride)\n",
    "  - Max pool layer: nn.Maxpool2d(kernel_size, stride, padding)\n",
    "  - Flatten layer: nn.Flatten()\n",
    "  - fully connected layer: nn.Linear(n_input, n_output)\n",
    "- Define the connections between layers in the *forward* method\n",
    "  - Don't forget to add the activation functions\n",
    "    - ReLU: F.relu()\n",
    "    - Sigmoid: F.sigmoid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GPU support\n",
    "# See https://pytorch.org/ for more info\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "\n",
    "        # TODO\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # TODO\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the training loop\n",
    "\n",
    "Now that you have the dataset and the model, you have to perform the training. It includes make predictions with the forward pass, calculating the loss between predictions and ground truths, and performing the parameters update with backpropagation.\n",
    "\n",
    "In PyTorch, you have to perform each steps explicitly in a *fit* function.\n",
    "In the code below, the fit function is completed for the training set. The steps are:\n",
    "- Extract batches from the data loader\n",
    "- Get predictions from batch\n",
    "- Calculate loss and gradients\n",
    "- Perform backpropagation\n",
    "- Repeat for all datasets and all epochs.\n",
    "\n",
    "**Your work:**\n",
    "- Complete the *fit* function to incorporate the validation set:\n",
    "- For each epoch:\n",
    "    - Get predictions on the validation set\n",
    "    - Calculate loss\n",
    "    - Store validation loss\n",
    "- No backpropagation is performed on the validation set\n",
    "    - Use `with torch.no_grad():` to avoid computing the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Criterion -> Loss function. Here we use the Cross Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer -> Optimisation used to update the parameters. Here we use Stochastic Gradient Descent\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs to perform the backpropagation on the whole train_set\n",
    "n_epochs = 5\n",
    "\n",
    "def fit(model, train_set, validation_set, n_epochs, criterion, optimizer):\n",
    "    train_loss = np.zeros(n_epochs)\n",
    "    val_loss = 0 #TODO\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_set, 0):\n",
    "\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() # Compute the gradients for all the parameters of the model using chain rule calculus\n",
    "            optimizer.step() # Perform the parameter update (param' = param - lr*gradient)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            train_loss[epoch] += loss.item()\n",
    "            if i % 1000 == 999:    # print every X mini-batches\n",
    "                print(f'[{epoch + 1}/{n_epochs} epochs, {i + 1:5d}/{len(train_set)} samples] -> loss: {running_loss / 1000:.3f}')\n",
    "                running_loss = 0.0\n",
    "        train_loss[epoch] = train_loss[epoch] / len(train_set)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pass\n",
    "\n",
    "            # TODO: Get validation set loss through each epoch.\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return model, train_loss, val_loss\n",
    "\n",
    "model, train_loss, val_loss = fit(model,train_loader,val_loader,n_epochs,criterion,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss, val_loss):\n",
    "    plt.plot(train_loss, label='Training loss')\n",
    "    plt.plot(val_loss, label='validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"CNN training\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction\n",
    "\n",
    "Now that you have trained your model, you can verify its performance on the field.  \n",
    "To do so, you can use the **test set**. You can compute the accuracy performance for the whole set, which will give a good representation of the model capability in a production environment.  \n",
    "For now, just printing the prediction for a few images will be enough.  \n",
    "The model outputs class probabilities in the format of a **one hot encoded vector**. In order to get the prediction of the model, you have to extract the maximum probability.  \n",
    "\n",
    "- *Complete the predict function below to return the class predicted by the model in the form of a string*\n",
    "- Remember the *classes* variable at the start of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, images, classes):\n",
    "    one_hot_encoded_outputs = model(images).detach().numpy()\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "    pass\n",
    "    \n",
    "\n",
    "\n",
    "# get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Make the prediction\n",
    "prediction = predict(model,images,classes)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\"LABEL / PREDICTION\")\n",
    "print(''.join(f'{classes[labels[j]]:5s} / {prediction[j]:5s}\\n' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BONUS - Foundation models\n",
    "\n",
    "In the previous sections, you learned how to train your own custom architecture from scratch.  \n",
    "All the weights were randomly initialised, and the model started its training with no apriori of the dataset.  \n",
    "\n",
    "During the course, we saw multiple architectures (AlexNet, VGG, ResNet...). These models were trained on large databases, and can be **fine-tuned** for your specific needs. These large-scale neural networks, pre-trained on extensive datasets are called **fundation models**.  \n",
    "\n",
    "In computer vision, you typically recover the pre-trained convolutional layers of the foundation model and then adapt the fully connected layers to your specific needs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the AlexNet model. After downloading the model from PyTorch, we can display the model's different layers by simply calling it in Python.   \n",
    "\n",
    "What can you tell from the output of the code below?    \n",
    "See how you can select only a subpart of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an AlexNet architecture\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "tmp_model = models.alexnet(weights=\"IMAGENET1K_V1\")\n",
    "print(tmp_model)\n",
    "#print(tmp_model.features)\n",
    "#print(tmp_model.avgpool)\n",
    "#print(tmp_model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with our CIFAR-10 example\n",
    "\n",
    "**Your job:**\n",
    "\n",
    "- Complete the **FoundationNet** class below to incorporate the foundation model of your choice\n",
    "- Check the PyTorch models page and select a model that suits your application `https://pytorch.org/vision/main/models.html`\n",
    "- Load a pre-trained model\n",
    "- Remove the fully connected layers\n",
    "    - This step depends on the function model you choose. Don't hesitate to check online for your specific approach\n",
    "    - Use the knowledge of the model architecture to switch the detection head\n",
    "- Add your own fully connected architecture that fits your use case\n",
    "- Initialise your model with the FundationNet class\n",
    "- Train/Test your new model\n",
    "- Compare the results with the moel trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class FoundationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO\n",
    "        \n",
    "        pass\n",
    "\n",
    "foundation_model = FoundationNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the fundation model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.SGD(foundation_model.parameters(), lr=learning_rate)\n",
    "n_epochs = 5\n",
    "\n",
    "foundation_model, train_loss, val_loss = fit(foundation_model,train_loader,val_loader,n_epochs,criterion,optimizer)\n",
    "plot_losses(train_loss, val_loss)\n",
    "\n",
    "# get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Make the prediction\n",
    "prediction = predict(foundation_model,images,classes)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\"LABEL / PREDICTION\")\n",
    "print(''.join(f'{classes[labels[j]]:5s} / {prediction[j]:5s}\\n' for j in range(batch_size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
